{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from urllib.request import urlopen\n",
    "from webbrowser import open as urldisplay\n",
    "import re\n",
    "from sqlite3 import *\n",
    "window = tk.Tk()\n",
    "window.configure(bg='#85d3e0')\n",
    "window.title(\"Showing Latest News\")\n",
    "var = tk.IntVar()\n",
    "\n",
    "#Dividing the entire screen into two frame:Left and Right\n",
    "\n",
    "left = tk.Frame(window,highlightbackground=\"black\", highlightthickness=2,borderwidth = 1)   \n",
    "left.pack(side=tk.LEFT, expand=True,padx=5,pady=5)\n",
    "\n",
    "\n",
    "photo = tk.PhotoImage(file =\"the_science-n-tech.png\") \n",
    "imgLabel = tk.Label(left, image=photo,borderwidth = 1,highlightbackground=\"black\",highlightthickness=1)\n",
    "imgLabel.pack(side=tk.TOP,padx=20,pady=20)\n",
    "\n",
    "\n",
    "\n",
    "# Frame to hold check_source and export button\n",
    "\n",
    "fram_button = tk.Frame(left,borderwidth=16)\n",
    "fram_button.pack(side = tk.BOTTOM)\n",
    "\n",
    "news = tk.Label(left,text='choose a news source to get tech news:',width=90,height= 2,fg='black',font = (\"Helvetica\",15))\n",
    "news.pack(side=tk.TOP,padx=10,pady=10)\n",
    "\n",
    "\n",
    "def bbc_news():\n",
    "  \n",
    "    headline_entry.delete(\"1.0\",\"end\")\n",
    "    article_entry.delete(\"1.0\",\"end\")\n",
    "    article_data.delete(\"1.0\",\"end\")\n",
    "    url1 = 'https://www.bbc.com/news/science_and_environment'#the latest news will be extracted from this site\n",
    "    bbc_page = urlopen(url1)\n",
    "\n",
    "    \n",
    "    html_code_bbc=bbc_page.read().decode('UTF-8')\n",
    "    \n",
    "\n",
    "    bbc_page.close()\n",
    "\n",
    "\n",
    "\n",
    "    start_marker = '<h3 class=\"gs-c-promo-heading__title gel-paragon-bold gs-u-mt+ nw-o-link-split__text\">'\n",
    "    end_marker = '</h3>'\n",
    "\n",
    "\n",
    "    start_position = html_code_bbc.find(start_marker)\n",
    "\n",
    "    end_position = html_code_bbc.find(end_marker)\n",
    "    # extracting news headline\n",
    "    try:\n",
    "     if start_position != -1 or end_position != -1:\n",
    "      title = html_code_bbc[start_position + len(start_marker) : end_position].upper()\n",
    "      if('&#x27;' in title):\n",
    "            title = title.replace('&#x27;',\"'\")\n",
    "      headline_entry.insert(tk.END, title) \n",
    " \n",
    "    except Exception as e:\n",
    "        headline_entry.insert(tk.END, e)\n",
    "     \n",
    "        \n",
    "\n",
    "    #searching for news Contents\n",
    "    start_marker =  'p class=\"gs-c-promo-summary gel-long-primer gs-u-mt nw-c-promo-summary\">'\n",
    "    end_marker = '</p>'\n",
    "    end_position = 0\n",
    "    try:\n",
    "     start_position = html_code_bbc.find(start_marker, end_position)  \n",
    "     end_position = html_code_bbc.find(end_marker, start_position)     \n",
    "     content_body = html_code_bbc[start_position + len(start_marker) : end_position]\n",
    "     if('&#x27;' in content_body):\n",
    "            content_body = content_body.replace('&#x27;',\"'\")\n",
    "     article_entry.insert(tk.END, content_body)\n",
    "\n",
    "    except Exception as e:\n",
    "        article_entry.insert(tk.END, e)\n",
    "\n",
    "      \n",
    "      # finding the date and time \n",
    "    \n",
    "    start_marker =  'data-datetime='\n",
    "    end_marker = '</time></span>'\n",
    "    end_position = 0\n",
    "    try:\n",
    "      start_position = html_code_bbc.find(start_marker, end_position)  \n",
    "      end_position = html_code_bbc.find(end_marker, start_position)      \n",
    "      time_unfilter  = html_code_bbc[start_position + len(start_marker) : end_position]\n",
    "      time_filter = time_unfilter.split('<span class=\"gs-u-vh\">')\n",
    "      time_h = time_filter[1]\n",
    "      time_h = time_h.strip()\n",
    "      time_h = time_h.split('</span>')[0]\n",
    "      time = \"Date and time: \"+ time_h+\"\\n\"\n",
    "      article_data.insert(tk.END, time)\n",
    "\n",
    "    except Exception as e:\n",
    "         article_data.insert(tk.END, e)\n",
    " \n",
    "      # finding the source\n",
    "    start_marker = '<title>'\n",
    "    end_marker = '</title>'\n",
    "    end_position = 0\n",
    "    try:\n",
    "      start_position = html_code_bbc.find(start_marker, end_position) \n",
    "      end_position = html_code_bbc.find(end_marker, start_position)\n",
    "      source_filter  = html_code_bbc[start_position + len(start_marker) : end_position]\n",
    "      source_filter = source_filter.split('-')\n",
    "      source = source_filter[1]\n",
    "      source_name = \"News Source:  \" + source+\"\\n\"\n",
    "\n",
    "    except Exception as e:\n",
    "        article_data.insert(tk.END, e) \n",
    "     \n",
    "    \n",
    "    \n",
    "      # finding the hostname for BBC news \n",
    "    start_marker = '<meta property=\"og:url\" content=\"https://'\n",
    "    end_marker = '/>'\n",
    "    end_position = 0\n",
    "    try:\n",
    "     start_position = html_code_bbc.find(start_marker, end_position)  \n",
    "     end_position = html_code_bbc.find(end_marker, start_position)\n",
    "     hostname  = html_code_bbc[start_position + len(start_marker) : end_position]\n",
    "     host = hostname.split('/')\n",
    "     host = host[0]\n",
    "     host_name = host.strip('\"')\n",
    "     host_name = \"Host name:  \" + host_name+\"\\n\"\n",
    "     article_data.insert(tk.END, host_name)  \n",
    "    except Exception as e:\n",
    "        article_data.insert(tk.END, e) \n",
    "    \n",
    "      # finding URL\n",
    "\n",
    "    start_marker = '<meta property=\"og:url\" content='\n",
    "    end_marker = '/>'\n",
    "    end_position = 0\n",
    "    try:\n",
    "     start_position = html_code_bbc.find(start_marker, end_position) \n",
    "     end_position = html_code_bbc.find(end_marker, start_position)\n",
    "     URL = html_code_bbc[start_position + len(start_marker) : end_position]\n",
    "     URL = URL.replace(\"\\\"\", \"\")  \n",
    "     url_name = \"URL:  \" + URL+\"\\n\"\n",
    "     article_data.insert(tk.END, url_name)\n",
    "    except Exception as e:\n",
    "        article_data.insert(tk.END, e)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "           ###################Washington news details ########################################\n",
    "\n",
    "\n",
    "\n",
    "def washington_news():\n",
    "    \n",
    "    headline_entry.delete(\"1.0\",\"end\")\n",
    "    article_entry.delete(\"1.0\",\"end\")\n",
    "    article_data.delete(\"1.0\",\"end\")\n",
    "    url2 ='https://www.washingtonpost.com/world/?hp_top_nav_world'\n",
    "    washington_page = urlopen(url2)\n",
    "    html_code_washington = washington_page.read().decode('UTF-8')\n",
    "    washington_page.close()\n",
    "    \n",
    "                #finding the news headine \n",
    "    start_marker = '<h2 class=\"headline x-small normal-style text-align-inherit \">'\n",
    "    end_marker = '</h2>'\n",
    "    start_position = html_code_washington.find(start_marker)\n",
    "    end_position = html_code_washington.find(end_marker)\n",
    "\n",
    "\n",
    "    try:\n",
    "      if start_position != -1 or end_position != -1:\n",
    "         title_unfilterd = html_code_washington[start_position + len(start_marker) : end_position]\n",
    "         title_unfilterd =  title_unfilterd.split(\">\")\n",
    "         title =  title_unfilterd[1].strip(\"</a>\")\n",
    "         if('&#x27;' in title):\n",
    "            title = title.replace('&#x27;',\"'\")\n",
    "         headline_entry.insert(tk.END, title)\n",
    "    except Exception as e:\n",
    "        headline_entry.insert(tk.END, e)\n",
    "     \n",
    " \n",
    "             #Searching for news Contents\n",
    "    start_marker =  '<div class=\"blurb normal normal-style \">'\n",
    "    end_marker = '</div>'\n",
    "    end_position = 0\n",
    "    try:\n",
    "      start_position = html_code_washington.find(start_marker, end_position)  \n",
    "      end_position =html_code_washington.find(end_marker, start_position)    \n",
    "      content_body = html_code_washington[start_position + len(start_marker) : end_position]\n",
    "      if('&#x27;' in content_body):\n",
    "            content_body = content_body.replace('&#x27;',\"'\")\n",
    "      article_entry.insert(tk.END, content_body)\n",
    "    except Exception as e:\n",
    "       article_entry.insert(tk.END, e)\n",
    "\n",
    "      \n",
    "                 # finding the date and time \n",
    "    start_marker =  '<li class=\"timestamp time\" data-timestamp='\n",
    "    end_marker = '</li></ul>'\n",
    "    end_position = 0\n",
    "    try:\n",
    "     start_position =html_code_washington.find(start_marker, end_position)  \n",
    "     end_position = html_code_washington.find(end_marker, start_position)    \n",
    "     time_unfiltered  =  html_code_washington[start_position + len(start_marker) : end_position] \n",
    "     time_filter = time_unfiltered.split(\">\")\n",
    "     time = time_filter[1]\n",
    "     date_time = \"Date and time: \" + time + '\\n'\n",
    "     article_data.insert(tk.END, date_time)\n",
    "    except Exception as e:\n",
    "        article_data.insert(tk.END, e)\n",
    "    \n",
    "    \n",
    "                    # finding the news source\n",
    "    start_marker = '<title>'\n",
    "    end_marker = '</title>'\n",
    "    end_position = 0\n",
    "    try:\n",
    "     start_position = html_code_washington.find(start_marker, end_position)   \n",
    "     end_position = html_code_washington.find(end_marker, start_position)\n",
    "     source_filter  = html_code_washington[start_position + len(start_marker) : end_position]\n",
    "     source_filter = source_filter.split('-')\n",
    "     source = source_filter[1]\n",
    "     source_name = \"News Source:  \" + source+\"\\n\"\n",
    "     article_data.insert(tk.END, source_name)\n",
    "    except Exception as e:\n",
    "        article_data.insert(tk.END, e)\n",
    "     \n",
    "    \n",
    "    \n",
    "      # finding the hostname\n",
    "    start_marker = '<meta property=\"og:url\" content=\"https://'\n",
    "    end_marker = '/>'\n",
    "    end_position = 0\n",
    "    try:\n",
    "      start_position = html_code_washington.find(start_marker, end_position)  \n",
    "      end_position = html_code_washington.find(end_marker, start_position)\n",
    "      hostname  = html_code_washington[start_position + len(start_marker) : end_position]\n",
    "      host = hostname.split('/')\n",
    "      host = host[0]\n",
    "      host_name = host.strip('\"')\n",
    "      host_name = \"Host name:  \" + host_name+\"\\n\"\n",
    "      article_data.insert(tk.END, host_name)\n",
    "    except Exception as e:\n",
    "        article_data.insert(tk.END, e)\n",
    "    \n",
    "      # finding URL\n",
    "\n",
    "    start_marker = '<meta property=\"og:url\" content='\n",
    "    end_marker = '/>'\n",
    "    end_position = 0\n",
    "    try:\n",
    "      start_position = html_code_washington.find(start_marker, end_position)  \n",
    "      end_position = html_code_washington.find(end_marker, start_position)\n",
    "      URL = html_code_washington[start_position + len(start_marker) : end_position]\n",
    "      URL = URL.strip('\"')\n",
    "      url_name = \"URL: \" + URL +\"\\n\"\n",
    "      article_data.insert(tk.END, url_name)\n",
    "    except Exception as e:\n",
    "         article_data.insert(tk.END, e)\n",
    "    \n",
    "     \n",
    "    \n",
    "    \n",
    "    \n",
    "###################phy_org_news details  ########################################\n",
    "\n",
    "\n",
    "\n",
    "def phy_org_news():\n",
    "    \n",
    "    headline_entry.delete(\"1.0\",\"end\")\n",
    "    article_entry.delete(\"1.0\",\"end\")\n",
    "    article_data.delete(\"1.0\",\"end\")\n",
    "    url3 = 'https://phys.org/earth-news/'\n",
    "    phy_org_page = urlopen(url3)\n",
    "    html_code_phy_org= phy_org_page.read().decode('UTF-8')\n",
    "    phy_org_page.close()\n",
    "    start_marker = '<h3 class=\"mb-1 mb-lg-2\">'\n",
    "    end_marker = '</h3>'\n",
    "\n",
    "\n",
    "    start_position = html_code_phy_org.find(start_marker)\n",
    "\n",
    "    end_position = html_code_phy_org.find(end_marker,start_position)\n",
    "\n",
    "\n",
    "    try: \n",
    "     if start_position != -1 or end_position != -1:\n",
    "        headline_news = html_code_phy_org[start_position + len(start_marker) : end_position].upper()\n",
    "        headline_filter = headline_news.split(\">\")\n",
    "        title_filter = headline_filter[1]\n",
    "        title = title_filter.split('</A')[0]\n",
    "        if('&#x27;' in title):\n",
    "            title = title.replace('&#x27;',\"'\")\n",
    "        headline_entry.insert(tk.END, title)    \n",
    "    except Exception as e:\n",
    "        headline_entry.insert(tk.END, e)\n",
    "          \n",
    "                   #Searching for Contents\n",
    "    start_marker = '<p class=\"mb-1 pr-1\">'\n",
    "    end_marker = '</p>'\n",
    "    end_position = 0\n",
    "    try:\n",
    "     start_position = html_code_phy_org.find(start_marker, end_position) \n",
    "     end_position = html_code_phy_org.find(end_marker, start_position)     \n",
    "     content_body = html_code_phy_org[start_position + len(start_marker) : end_position]\n",
    "     content_body = content_body.strip()\n",
    "     if('&#x27;' in content_body):\n",
    "        content_body = content_body.replace('&#x27;',\"'\")\n",
    "     article_entry.insert(tk.END, content_body)\n",
    "    except Exception as e:\n",
    "        article_entry.insert(tk.END, e)\n",
    "      \n",
    "                            # finding the date and time \n",
    "    start_marker =  '<div class=\"article__info-item mr-3\">'\n",
    "    end_marker = '</div>'\n",
    "    end_position = 0\n",
    "    try:\n",
    "      start_position = html_code_phy_org.find(start_marker, end_position)  \n",
    "      end_position = html_code_phy_org.find(end_marker, start_position)    \n",
    "      time_unfilter  =  html_code_phy_org[start_position + len(start_marker) : end_position] \n",
    "      time_filter = time_unfilter.split('<p class=\"text-uppercase text-low\">')\n",
    "      time = time_filter[1].strip('\\n')\n",
    "      time = time.strip()\n",
    "      time = time.strip('</p>')\n",
    "      date_time = \"Date and time: \" + time + '\\n'\n",
    "      article_data.insert(tk.END, date_time)\n",
    "    except Exception as e:\n",
    "             article_data.insert(tk.END, e)\n",
    "    \n",
    "    \n",
    "      # finding the source\n",
    "    start_marker = '<meta property=\"og:url\" content=\"https://'\n",
    "    end_marker = '/>'\n",
    "    end_position = 0\n",
    "    try:\n",
    "      start_position = html_code_phy_org.find(start_marker, end_position)  \n",
    "      end_position = html_code_phy_org.find(end_marker, start_position)\n",
    "      source  = html_code_phy_org[start_position + len(start_marker) : end_position]\n",
    "      source = source.split('/')\n",
    "      source = source[0]\n",
    "      source_name = \"News Source:  \" + source+\"\\n\"\n",
    "      article_data.insert(tk.END, source_name)\n",
    "    except Exception as e:\n",
    "             article_data.insert(tk.END, e)\n",
    "    \n",
    "    \n",
    "      # finding the hostname\n",
    "    start_marker = '<meta property=\"og:url\" content=\"https://'\n",
    "    end_marker = '/>'\n",
    "    end_position = 0\n",
    "    try:\n",
    "      start_position = html_code_phy_org.find(start_marker, end_position) \n",
    "      end_position = html_code_phy_org.find(end_marker, start_position)\n",
    "      hostname  = html_code_phy_org[start_position + len(start_marker) : end_position]\n",
    "      host = hostname.split('/')\n",
    "      host = host[0]\n",
    "      host_name = host.strip('\"')\n",
    "      host_name = \"Host name:  \" + host_name+\"\\n\"\n",
    "      article_data.insert(tk.END, host_name)\n",
    "    except Exception as e:\n",
    "             article_data.insert(tk.END, e)\n",
    "    \n",
    "      # finding URL\n",
    "\n",
    "    start_marker = '<meta property=\"og:url\" content='\n",
    "    end_marker = '/>'\n",
    "    end_position = 0\n",
    "    try:\n",
    "      start_position = html_code_phy_org.find(start_marker, end_position)  \n",
    "      end_position = html_code_phy_org.find(end_marker, start_position)\n",
    "      URL = html_code_phy_org[start_position + len(start_marker) : end_position]\n",
    "   \n",
    "      URL = URL.replace(\"\\\"\", \"\") \n",
    "      url_name = \"URL:  \" + URL+\"\\n\"\n",
    "      article_data.insert(tk.END, url_name)\n",
    "    except Exception as e:\n",
    "            article_data.insert(tk.END, e)\n",
    "     \n",
    "   \n",
    "\n",
    "def japantimes_news():\n",
    "    \n",
    "    headline_entry.delete(\"1.0\",\"end\")\n",
    "    article_entry.delete(\"1.0\",\"end\")\n",
    "    article_data.delete(\"1.0\",\"end\")\n",
    "    url3 = 'https://www.japantimes.co.jp/news/column/focus/'\n",
    "    japan_times_page = urlopen(url3)\n",
    "    html_code_japan_times= japan_times_page.read().decode('UTF-8')\n",
    "    japan_times_page.close()\n",
    "    start_marker = '<p><a href=\"https://www.japantimes.co.jp/news'\n",
    "    end_marker = '</a></p>'\n",
    "\n",
    "\n",
    "    start_position = html_code_japan_times.find(start_marker)\n",
    "\n",
    "    end_position = html_code_japan_times.find(end_marker,start_position)\n",
    "\n",
    "\n",
    "    try: \n",
    "     if start_position != -1 or end_position != -1:\n",
    "        headline_news = html_code_japan_times[start_position + len(start_marker) : end_position].upper()\n",
    "        headline_filter = headline_news.split(\">\")\n",
    "        title = headline_filter[1].strip() \n",
    "        if('&#x27;' in title):\n",
    "            title = title.replace('&#x27;',\"'\")\n",
    "        headline_entry.insert(tk.END, title)    \n",
    "    except Exception as e:\n",
    "        headline_entry.insert(tk.END, e)\n",
    "          \n",
    "                   #Searching for Contents\n",
    "    start_marker = '<h5 class=\"writer\"'\n",
    "    end_marker = '<span class=\"icon-arrow-2\"></span></a>'\n",
    "    end_position = 0\n",
    "    try:\n",
    "     start_position = html_code_japan_times.find(start_marker, end_position)   \n",
    "     end_position = html_code_japan_times.find(end_marker, start_position)     \n",
    "     content_body = html_code_japan_times[start_position + len(start_marker) : end_position]\n",
    "     content_body = content_body.strip()\n",
    "   \n",
    "     content_body_filtered = content_body.strip().split('<p>')\n",
    "     content_body = content_body_filtered[1].strip()\n",
    "     content_body=content_body.split('<a href=')[0].strip()\n",
    "     if('&#x27;' in content_body):\n",
    "            content_body = content_body.replace('&#x27;',\"'\")\n",
    "     article_entry.insert(tk.END, content_body)\n",
    "    except Exception as e:\n",
    "        article_entry.insert(tk.END, e)\n",
    "      \n",
    "                            # finding the date and time \n",
    "    start_marker =  '<span class=\"right date\">'\n",
    "    end_marker = '</span>'\n",
    "    end_position = 0\n",
    "    try:\n",
    "      start_position = html_code_japan_times.find(start_marker, end_position)  \n",
    "      end_position = html_code_japan_times.find(end_marker, start_position)      \n",
    "      time_unfilter  =  html_code_japan_times[start_position + len(start_marker) : end_position] \n",
    "      time = time_unfilter.strip()\n",
    "      date_time = \"Date and time: \" + time + '\\n'\n",
    "      article_data.insert(tk.END, date_time)\n",
    "    except Exception as e:\n",
    "             article_data.insert(tk.END, e)\n",
    "    \n",
    "    \n",
    "      # finding the source\n",
    "    start_marker = '<title>'\n",
    "    end_marker = '</title>'\n",
    "    end_position = 0\n",
    "    try:\n",
    "      start_position = html_code_japan_times.find(start_marker, end_position)\n",
    "      end_position = html_code_japan_times.find(end_marker, start_position)\n",
    "      source  = html_code_japan_times[start_position + len(start_marker) : end_position]\n",
    "      source = source.split('-')\n",
    "      source = source[1].strip()\n",
    "      source_name = \"News Source:  \" + source+\"\\n\"\n",
    "      article_data.insert(tk.END, source_name)\n",
    "    except Exception as e:\n",
    "             article_data.insert(tk.END, e)\n",
    "    \n",
    "    \n",
    "      # finding the hostname\n",
    "    start_marker = '<meta property=\"og:url\" content=\"https://'\n",
    "    end_marker = '/>'\n",
    "    end_position = 0\n",
    "    try:\n",
    "      start_position = html_code_japan_times.find(start_marker, end_position)  \n",
    "      end_position = html_code_japan_times.find(end_marker, start_position)\n",
    "      hostname  = html_code_japan_times[start_position + len(start_marker) : end_position]\n",
    "      host = hostname.split('/')\n",
    "      host = host[0]\n",
    "      host_name = host\n",
    "      host_name = \"Host name:  \" + host_name+\"\\n\"\n",
    "      article_data.insert(tk.END, host_name)\n",
    "    except Exception as e:\n",
    "             article_data.insert(tk.END, e)\n",
    "    \n",
    "      # finding URL\n",
    "\n",
    "    start_marker = '<meta property=\"og:url\" content='\n",
    "    end_marker = '/>'\n",
    "    end_position = 0\n",
    "    try:\n",
    "      start_position = html_code_japan_times.find(start_marker, end_position)  \n",
    "      end_position = html_code_japan_times.find(end_marker, start_position)\n",
    "      URL = html_code_japan_times[start_position + len(start_marker) : end_position]\n",
    "   \n",
    "      URL = URL.replace(\"\\\"\", \"\") \n",
    "      url_name = \"URL:  \" + URL+\"\\n\"\n",
    "      article_data.insert(tk.END, url_name)\n",
    "    except Exception as e:\n",
    "            article_data.insert(tk.END, e)\n",
    "     \n",
    "   \n",
    "   \n",
    "   \n",
    "def checking_soure(): \n",
    "    selection = var.get()\n",
    "    if(selection == 1):\n",
    "        url = 'https://www.bbc.com/news/science_and_environment'\n",
    "        urldisplay(url)\n",
    "    elif(selection ==2):\n",
    "        url ='https://www.washingtonpost.com/world/?hp_top_nav_world'\n",
    "        urldisplay(url)\n",
    "    elif(selection ==3):\n",
    "        url = 'https://phys.org/earth-news/'  \n",
    "        urldisplay(url)\n",
    "    else:\n",
    "        url = 'https://phys.org/earth-news/'  \n",
    "        urldisplay(url)\n",
    "    \n",
    "def export_in_database():\n",
    "   \n",
    "  \n",
    "   news_details = article_data.get(1.0, \"end-1c\")\n",
    "   news_details  = news_details .split(\"\\n\")\n",
    "   news_headline = headline_entry.get(1.0,\"end-1c\")\n",
    "   news_body = article_entry.get(1.0,\"end-1c\")\n",
    "   news_date = news_details[0]\n",
    "   news_date = news_date.split(\":\")[1]\n",
    "   news_source = news_details[2]\n",
    "   news_source = news_source.split(\":\")[1]\n",
    "   # Create a connection to the database\n",
    "   connection = connect('selected-news.db')\n",
    "  # Get a pointer into the database\n",
    "   selected_news_db = connection.cursor()\n",
    "   selected_news_db.execute(\"insert into latest_news values(?,?,?,?)\",(news_date,news_headline,news_body,news_source))\n",
    "   connection.commit()                                                                                                            \n",
    "  \n",
    "   print('Number of rows affected:', selected_news_db.rowcount)\n",
    "   # Close the database\n",
    " \n",
    "   selected_news_db.close()\n",
    "   connection.close()\n",
    " \n",
    "\n",
    "# photo and radiobutton of news1\n",
    "\n",
    "\n",
    "photo1 = tk.PhotoImage(file =\"the_bbc.png\")\n",
    "photoimage1 = photo1.subsample(4, 4)\n",
    "bbc_news = tk.Radiobutton(left,text='bbc',image = photoimage1,width=80, variable=var,value =1, command = bbc_news)\n",
    "bbc_news.pack(side = tk.LEFT,padx=40, pady=40)\n",
    "\n",
    "\n",
    "# photo and radiobutton of news2\n",
    "photo2 = tk.PhotoImage(file =\"the_wp.png\")\n",
    "photoimage2 = photo2.subsample(4, 4)\n",
    "washington_news = tk.Radiobutton(left,text='The washington',image = photoimage2,width=150,variable=var,value=2,command=washington_news)\n",
    "washington_news.pack(side = tk.LEFT, padx=40, pady=40)\n",
    "\n",
    "\n",
    "\n",
    "# photo and radiobutton of news3\n",
    "photo3 = tk.PhotoImage(file =\"the_jt.png\")\n",
    "photoimage3 = photo3.subsample(4, 4)\n",
    "phy_org = tk.Radiobutton(left,text='The jt',image = photoimage3,variable=var,value=3,width=80,command = japantimes_news)\n",
    "phy_org.pack(side = tk.RIGHT,padx=40, pady=40)\n",
    "\n",
    "\n",
    "\n",
    "# photo and radiobutton of news4\n",
    "photo4 = tk.PhotoImage(file =\"the_phys.png\")\n",
    "photoimage4 = photo4.subsample(2,2)\n",
    "phy_org = tk.Radiobutton(left,text='Phys org',image = photoimage4,variable=var,value=4,width=80,command = phy_org_news)\n",
    "phy_org.pack(side = tk.RIGHT,padx=40, pady=40)\n",
    "\n",
    "\n",
    "# Right frame to show news display\n",
    "\n",
    "right = tk.Frame(window, height=900, width=700,highlightbackground=\"black\", highlightthickness=4,borderwidth = 1,bg='sea green')\n",
    "right.pack(side= tk.RIGHT,expand=True,padx=10,pady=10)\n",
    "\n",
    "l_news = tk.Label(right,text='Latest News',width=14,height= 2,fg='black',bg='sea green',font = (\"Helvetica\",20,'bold'))\n",
    "l_news.pack(side=tk.TOP,padx=10,pady=10)\n",
    "\n",
    "\n",
    "\n",
    "headline = tk.Label(right,text='Article Headline:',width=20,height= 2,fg='black',bg='sea green',font = (\"Helvetica\",20))\n",
    "headline.pack(padx=10,pady=10)\n",
    "\n",
    "\n",
    "\n",
    "headline_entry = tk.Text(right,height=3, width=100,bg='white',font = (\"Helvetica\",10))\n",
    "headline_entry.pack(padx=10,pady=10)\n",
    "\n",
    "\n",
    "\n",
    "article_body = tk.Label(right,text='Article Body:',width=20,height= 2,fg='black',bg='sea green',font = (\"Helvetica\",20))\n",
    "article_body.pack(padx=10,pady=10)\n",
    "\n",
    "\n",
    "article_entry = tk.Text(right,width=200,height=10,fg='black',bg='white',font=(\"Helvetica\",10))\n",
    "article_entry.pack(padx=10,pady=10)\n",
    "\n",
    "article_data = tk.Label(right,text='Article Data:',width=20,height= 2,fg='black',bg='sea green',font = (\"Helvetica\",20))\n",
    "article_data.pack(padx=10,pady=10)\n",
    "\n",
    "article_data = tk.Text(right,width=200,height=10 ,fg='black',bg='white',font=('Helvetica',10))\n",
    "article_data.pack(padx=10,pady=10)\n",
    "# details of two lower buttons \n",
    "chksource = tk.Button(fram_button,text=\"Check source\",width=14,height= 2,fg='black',font = (\"Helvetica\",20),command = checking_soure)\n",
    "chksource.pack(side = tk.LEFT,padx=40, pady=40)\n",
    "\n",
    "\n",
    "\n",
    " \n",
    "exportsel = tk.Button(fram_button,text=\"Export selection\",width=14,height= 2,fg='black',font = (\"Helvetica\",20),command = export_in_database)\n",
    "exportsel.pack(side = tk.RIGHT,padx=40, pady=40)\n",
    "\n",
    "window.mainloop()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
